# ğŸš€ í•™ìŠµ í‚¤ì›Œë“œ

í•µì‹¬ í‚¤ì›Œë“œ

    1.	ìˆœì°¨ ë°ì´í„° (Sequential Data)
      -	íŠ¹ì • ìˆœì„œë¥¼ ê°€ì§€ëŠ” ë°ì´í„° ì˜ˆ: ì‡¼í•‘ëª° êµ¬ë§¤ ëª©ë¡, ì˜í™” ì‹œì²­ ëª©ë¡, ìœ ì „ì ì„œì—´, ì£¼ì‹ ë“±
    2.	ì˜ˆì¸¡ ë¬¸ì œ (Forecasting Problem)
      -	ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œ
    3.	ë§ˆë¥´ì½”í”„ ê³¼ì • (Markov Process)
      -	ë¯¸ë˜ì˜ ìƒíƒœê°€ í˜„ì¬ ìƒíƒœì—ë§Œ ì˜ì¡´í•˜ëŠ” í™•ë¥  ê³¼ì •
    4.	ìƒíƒœ ì „ì´ í–‰ë ¬ (State Transition Matrix)
      -	ê° ìƒíƒœì—ì„œ ë‹¤ë¥¸ ìƒíƒœë¡œì˜ ì „í™˜ í™•ë¥ ì„ ë‚˜íƒ€ë‚´ëŠ” í–‰ë ¬
    5.	ì€ë‹‰ ë§ˆë¥´ì½”í”„ ëª¨ë¸ (Hidden Markov Model, HMM)
      -	ìˆ¨ê²¨ì§„ ìƒíƒœì— ì˜í•´ ê´€ì¸¡ ê°€ëŠ¥í•œ ì´ë²¤íŠ¸ê°€ ë°œìƒí•œë‹¤ê³  ê°€ì •í•˜ëŠ” í†µê³„ì  ëª¨ë¸

ì£¼ìš” ë¬¸ì œ

    1.	í‰ê°€ ë¬¸ì œ (Evaluation Problem)
      -	ì£¼ì–´ì§„ HMMê³¼ ê´€ì¸¡ëœ ì‹œí€€ìŠ¤ì˜ í™•ë¥ ì„ ê³„ì‚°í•˜ëŠ” ë¬¸ì œ, ì „ë°© ì•Œê³ ë¦¬ì¦˜(Forward Algorithm) ì‚¬ìš©
    2.	ë””ì½”ë”© ë¬¸ì œ (Decoding Problem)
      -	ì£¼ì–´ì§„ HMMê³¼ ê´€ì¸¡ëœ ì‹œí€€ìŠ¤ì— ëŒ€í•´ ê°€ì¥ ê·¸ëŸ´ë“¯í•œ ìˆ¨ê²¨ì§„ ìƒíƒœ ì‹œí€€ìŠ¤ë¥¼ ê²°ì •í•˜ëŠ” ë¬¸ì œ, ë¹„í…Œë¥´ë¹„ ì•Œê³ ë¦¬ì¦˜(Viterbi Algorithm) ì‚¬ìš©

ì•Œê³ ë¦¬ì¦˜

    -	ì „ë°© ì•Œê³ ë¦¬ì¦˜ (Forward Algorithm)
      -	HMMì—ì„œ ê´€ì¸¡ëœ ì‹œí€€ìŠ¤ê°€ ë‚˜íƒ€ë‚  í™•ë¥ ì„ ê³„ì‚°
    -	ë¹„í…Œë¥´ë¹„ ì•Œê³ ë¦¬ì¦˜ (Viterbi Algorithm)
      -	ì£¼ì–´ì§„ ê´€ì¸¡ ì‹œí€€ìŠ¤ì— ëŒ€í•´ ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ìˆ¨ê²¨ì§„ ìƒíƒœ ì‹œí€€ìŠ¤ë¥¼ ì°¾ìŒ

---

# ğŸ“ ìƒˆë¡œ ë°°ìš´ ê°œë…

## Sequential Data

- íŠ¹ì • ìˆœì„œë¥¼ ê°€ì§€ëŠ” ë°ì´í„°
- ex : ì‡¼í•‘ëª° êµ¬ë§¤ ëª©ë¡, ì˜í™” ì‹œì²­ ëª©ë¡, ìœ ì „ì ì„œì—´, ì£¼ì‹..ë“±

## Forecasting Problem

- ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œ
- N discrete states ì¤‘ í•˜ë‚˜ì˜ ìƒíƒœë¥¼ ê°–ëŠ” ì‹œìŠ¤í…œì„ ê³ ë ¤ -> $q_t \in$ { ${S_1, S_2, ..., S_N}$ }
- ì •ì˜ëœ ìƒíƒœëŠ” ëœë¤ìœ¼ë¡œ ë³€í•˜ëŠ” stochastic systems (í™•ë¥ ë¡ ì ì¸ ì‹œìŠ¤í…œ) ì´ë¼ê³  ê°€ì •
- ì‹œìŠ¤í…œì˜ ìƒíƒœëŠ” ê´€ì¸¡ë˜ì§€ ì•ŠëŠ” hidden stateì´ë©°, ê´€ì¸¡ë˜ëŠ” ê²ƒì€ observationì´ë‹¤.
  - ì´ë•Œ joint distribution(ê²°í•© í™•ë¥  ë¶„í¬)ëŠ” ê±°ì˜ ê³„ì‚° ë¶ˆê°€ëŠ¥í•˜ë‹¤ -> $p(q_0, q_1, ..., q_T) = P(q_0)P(q_1|q_0)P(q_2|q_1q_0)P(q_3|q_2q_1q_0)...$

```
ê²°í•© í™•ë¥  ë¶„í¬ : ì—¬ëŸ¬ í™•ë¥  ë³€ìˆ˜ê°€ ì·¨í•  ìˆ˜ ìˆëŠ” ëª¨ë“  ê°’ì˜ ì¡°í•©ì— ëŒ€í•œ í™•ë¥ ì„ ì„¤ëª…í•˜ëŠ” í™•ë¥  ë¶„í¬
- ex) P(A, B) = P(A)P(B|A) = P(B)P(A|B)
- ë‘ê°œ ì´ìƒì˜ í™•ë¥  ë³€ìˆ˜ê°€ ë™ì‹œì— ì–´ë–¤ ê°’ë“¤ì„ ì·¨í•  í™•ë¥ ì„ ë‚˜íƒ€ëƒ„
```

- íŠ¹ì • ìƒíƒœì˜ í™•ë¥  ê°’ì€ `ì´ì „ ìƒíƒœì˜ í™•ë¥  ê°’`ì„ ì•Œë©´ êµ¬í•  ìˆ˜ ìˆë‹¤.
- ê³¼ê±°ì˜ ëª¨ë“  ìƒíƒœë¥¼ êµ¬í•˜ëŠ” ê²ƒì€ ê±°ì˜ ë¶ˆê°€ëŠ¥í•˜ë‹¤ (ex: ë¹…ë±… -> ì¡°ì„  -> 10ì¼ì „ ë“±,,)

## Markov Property (Markov Assumption)

- ë‹¤ìŒ ë¯¸ë˜ì˜ ìƒíƒœëŠ” ì˜¤ì§ í˜„ì¬ ìƒíƒœì— ì˜í–¥ë§Œ ë°›ëŠ”ë‹¤(ê°€ì •)
  - $P(q_{t+1}|q_t,...,q_{0}) = P(q_{t+1}|q_t)$
- í˜„ì¬ ìƒíƒœê°€ ì£¼ì–´ì§€ê³  **ì´ì „ ê³¼ê±°ì˜ ìƒíƒœëŠ” ê³ ë ¤í•˜ì§€ ì•ŠëŠ”ë‹¤.**
- ë°”ë¡œ ì§ì „ì˜ ì •ë³´ê°€ ì¶©ë¶„íˆ ê³¼ê±°ì˜ ì •ë³´ë¥¼ ë‹´ê³  ìˆë‹¤ê³  ê°€ì •í•œë‹¤.
- í˜„ì¬ ìƒíƒœê°€ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë° ì¶©ë¶„í•œ ì •ë³´ë¥¼ ë‹´ê³  ìˆë‹¤ê³  ê°€ì •í•œë‹¤.

## Markov process

- **ëœë¤ í”„ë¡œì„¸ìŠ¤**ì´ë‹¤,
  - í™•ë¥ ì ì¸ ì‹œìŠ¤í…œì˜ ì¼ì¢…ìœ¼ë¡œ ë¯¸ë˜ì˜ ìƒíƒœê°€ ì˜¤ì§ í˜„ì¬ ìƒíƒœì—ë§Œ ì˜ì¡´í•˜ë©´ ê³¼ê±°ì˜ ìƒíƒœë‚˜ ì–´ë–»ê²Œ í˜„ì¬ ìƒíƒœì— ì´ë¥´ë €ëŠ”ì§€ëŠ” ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠëŠ” ê³¼ì •ì„ ë§í•¨
- í™•ë¥ ì ì¸ í–‰ë™(Stochastic behavior)ì„ í‘œí˜„, ì—°ì†ì ì¸ í–‰ë™ì˜ ë³€í™”ë¥¼ ê´€ì°°
  - a finite set of N states, $S =$ { ${S_1, S_2, ..., S_N}$ }
  - a state transition probability, $P = {p_{ij}}_{M * M}, 1 \leq i, j \leq M$
  - an initial state distribution, $\pi =$ { $\pi_i$ }

```
ì „ì´ í™•ë¥  (Transition Probability) : í•œ ìƒíƒœì—ì„œ ë‹¤ë¥¸ ìƒíƒœë¡œ ì´ë™í•  í™•ë¥ 
- ì´ í™•ë¥ ì€ ìƒíƒœê°„ì˜ ì „ì´ë¥¼ ê²°ì • ì§“ëŠ” í•µì‹¬ ìš”ì†Œ
```

## State Transition Matrix

- Markov state sì™€ ì„±ê³µ ìƒíƒœ s'ì— ëŒ€í•´, ìƒíƒœ ë³€í™” í™•ë¥ ì€ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜
  - $P_{ss'} = P(S_{t+1} = s' | S_t = s)$
  - ì¦‰, ìƒíƒœê°€ ë³€í™”í•¨ì„ í™•ë¥ ë¡œ í‘œí˜„í•œ í–‰ë ¬

```
- Markov state : ë§ˆë¥´ì½”í”„ ê³¼ì •ì—ì„œ íŠ¹ì • ì‹œê°„ tì—ì„œ ì‹œìŠ¤í…œì´ ì·¨í•  ìˆ˜ ìˆëŠ” ìƒíƒœë¥¼ ë‚˜íƒ€ëƒ„
    - ì´ ìƒíƒœì—ì„œ ì‹œìŠ¤í…œì€ ë‹¤ìŒ ìƒíƒœë¡œ ì´ë™í•  í™•ë¥ ì´ ì •ì˜
- ì„±ê³µ ìƒíƒœ s' : ì£¼ì–´ì§„ ìƒíƒœ sì—ì„œ ë‹¤ìŒ ì‹œê°„ t+1ì—ì„œ ì‹œìŠ¤í…œì´ ì·¨í•  ìˆ˜ ìˆëŠ” ìƒíƒœ ì¤‘ í•˜ë‚˜
    - í˜„ì¬ ìƒíƒœ së§Œì´ ë¯¸ë˜ ìƒíƒœ s'ì— ì˜í–¥ì„ ì¤€ë‹¤ëŠ” ê²ƒì´ë©°, ê³¼ê±°ì˜ ì–´ë–¤ ìƒíƒœë„ s'ì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠëŠ”ë‹¤.
```

- ìƒíƒœë³€í™” í–‰ë ¬ PëŠ” ëª¨ë“  ìƒíƒœ së¡œë¶€í„° ë‹¤ìŒ ìƒíƒœë¡œ s'ë¡œ ë³€í• (ì „í™˜ë ) í™•ë¥ ì„ ì •ì˜
- ê° í–‰ê³¼ ì—´ì´ ë§ˆë¥´ì½”í”„ ì²´ì¸ì˜ ìƒíƒœë¥¼ ë‚˜íƒ€ëƒ„
  - ê° í–‰ì€ í˜„ì¬ ìƒíƒœì—ì„œ ì¶œë°œí•˜ì—¬ ë‹¤ë¥¸ ìƒíƒœë¡œ ì´ë™í•  í™•ë¥ 
  - ê° ì—´ì€ ë„ì°© ìƒíƒœë¥¼ ë‚˜íƒ€ëƒ„
  - $$ P = \begin{bmatrix} p*{11} & p*{12} & ... & p*{1n} \\ p*{21} & p*{22} & ... & p*{2n} \\ ... & ... & ... & ... \\ p*{n1} & p*{n2} & ... & p\_{nn} \end{bmatrix}$$
- íŠ¹ì§•
  - `ê° í–‰ì˜ í•©ì€ 1 ì´ë‹¤` : ì–´ë–¤ ìƒíƒœì—ì„œ ë‹¤ë¥¸ ëª¨ë“  ìƒíƒœë¡œì˜ ì „í™˜ í™•ë¥ ì˜ í•©ì´ í•­ìƒ 1ì´ ë˜ì–´ì•¼ í•œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸, ì–´ë–¤ ìƒíƒœì—ì„œ ë¬´ì¡°ê±´ ë‹¤ë¥¸ ìƒíƒœë¡œ ì´ë™í•´ì•¼ í•˜ê¸° ë•Œë¬¸
    - $\sum_{j \in s}{} p_{ij} = 1$
  - `ë¹„ìŒìˆ˜` : ëª¨ë“  ì „í™˜ í™•ë¥ ì€ ìŒìˆ˜ê°€ ì•„ë‹Œ ê°’ì´ì–´ì•¼ í•œë‹¤.

## Hidden Markov Model (HMM)

- ê´€ì¸¡ ê°€ëŠ¥í•œ ì´ë²¤íŠ¸ë“¤ì´ ë‚´ë¶€ì ì¸ ìˆ¨ê²¨ì§„ ìƒíƒœì— ì˜í•´ ìƒì„±ëœë‹¤ê³  ê°€ì •í•˜ëŠ” í†µê³„ì  ëª¨ë¸
  - ê°„ë‹¨í•˜ê²Œ ë§í•´ **ê°™ì€ ì‹œê°„(ë™ì‹œì—)** ì— ë°œìƒí•œ ë‘ ì¢…ë¥˜ì˜ state sequence ê°ê°ì˜ íŠ¹ì„±ê³¼ ê·¸ë“¤ì˜ ê´€ê³„ë¥¼ ëª¨ë¸ë§

```
state sequence : ì‹œê°„ì— ë”°ë¼ ë‚˜íƒ€ë‚˜ëŠ” ì¼ë ¨ì˜ ìƒíƒœë“¤ì„ ì˜ë¯¸
- ê° ì‹œê°„ ë‹¨ê³„ì—ì„œ ìƒíƒœê°€ ë°”ë€” ìˆ˜ ìˆëŠ” í™•ë¥ ì  í”„ë¡œì„¸ìŠ¤, ë‹¤ìŒ ìƒíƒœëŠ” ì˜¤ì§ í˜„ì¬ ìƒíƒœì—ë§Œ ì˜ì¡´í•˜ëŠ” 'ë¬´ê¸°ì–µì„±' ì†ì„±ì„ ê°€ì§
```

- **Markov Model** : stateë¡œ ì´ë£¨ì–´ì§„ Sequenceë¥¼ ìƒíƒœ ì „ì´ í™•ë¥  í–‰ë ¬ë¡œ í‘œí˜„í•˜ëŠ” ê²ƒ

### HMM êµ¬ì„±ìš”ì†Œ

1. Hidden States Sequence (ìˆ¨ê²¨ì§„ ìƒíƒœ ì‹œí€€ìŠ¤)
   - ëª¨ë¸ì˜ ë‚´ë¶€ ìƒíƒœë¥¼ ë‚˜íƒ€ë‚´ë©°, ì§ì ‘ ê´€ì¸¡í•  ìˆ˜ ì—†ë‹¤.
   - $(S_1, S_2, ..., S_{t-1}, S_t)$
   - `Markov assumption`ì„ ë”°ë¦„ -> ìˆœì°¨ì  íŠ¹ì„±ì„ ë°˜ì˜
2. Observable States Sequence (ê´€ì¸¡ ê°€ëŠ¥í•œ ìƒíƒœ ì‹œí€€ìŠ¤)
   - ìˆ¨ê²¨ì§„ ìƒíƒœì— ì˜í•´ ì˜í–¥ì„ ë°›ëŠ” ê´€ì¸¡ ê°€ëŠ¥í•œ ì´ë²¤íŠ¸ë“¤ì˜ ì‹œí€€ìŠ¤
   - $(S_{1}^{'}, S_{2}^{'}, ..., S_{t-1}^{'}, S_t^{'})$
   - ìˆœì°¨ì  íŠ¹ì„±ì„ ë°˜ì˜í•˜ëŠ” Hidden stateì— ì¢…ì†

### HMM: Parameters

- Parameters of a Hidden Markov Model : $\lambda = (A, B, \pi)$

1. $A(a_{ij})$ : ìƒíƒœ ì „ì´ í™•ë¥  í–‰ë ¬ (State Transition Probability Matrix)
   - í•œ ìˆ¨ê²¨ì§„ ìƒíƒœ iì—ì„œ ë‹¤ë¥¸ ìˆ¨ê²¨ì§„ ìƒíƒœ jë¡œ ì´ë™í•  í™•ë¥ ì„ ì •ì˜
   - $a_{ij} = P(S_{t+1} = j | S_t = i)$ , $1 \leq i, j \leq n$
   - $\sum*{j=1}^{n} a*{ij} = 1$
2. $B(b_{jk})$ : ë°©ì¶œ í™•ë¥  í–‰ë ¬ (Emission Probability Matrix)
   - íŠ¹ì • ìˆ¨ê²¨ì§„ ìƒíƒœ jì—ì„œ ê° ê´€ì¸¡ ê°€ëŠ¥í•œ ìƒíƒœ kê°€ ë‚˜íƒ€ë‚  í™•ë¥ ì„ ì •ì˜ (ì€ë‹‰ ìƒíƒœ bjì—ì„œ ê´€ì¸¡ì¹˜ê°€ vkê°€ ë„ì¶œë  í™•ë¥ )
   - $b_j(vk) = P(o_t = v_k | q_t = s_j)$, $1 \leq j \leq n, 1 \leq k \leq m$
   - $\sum\_{j=1}^{n} b_j(v_k) = 1$
3. $\pi = (\pi _ {i})$ : ì´ˆê¸° ìƒíƒœ í™•ë¥  (Initial State Probability)
   - ì‹œí€€ìŠ¤ì˜ ì‹œì‘ì—ì„œ ê° ìˆ¨ê²¨ì§„ ìƒíƒœë¥¼ ê°–ê²Œ ë  í™•ë¥ ì„ ì •ì˜
   - $\pi$ -> HMMì„ ê°€ë™ ì‹œí‚¬ ë•Œ ì–´ëŠ ìƒíƒœì—ì„œ ì‹œì‘í•  ì§€ ê²°ì •
   - $\pi_i -> s_i$ì—ì„œ ì‹œì‘í•  í™•ë¥ 
   - $\sum\_{i=1}^{n} \pi_i = 1$

## HMM Problems

### Evaluation problem

- problem ( í‰ê°€ ë¬¸ì œ ) : HMM($\lambda$)ê³¼ Oê°€ ì£¼ì–´ì¡Œì„ ë•Œ Observable sequence O'ì˜ í™•ë¥  (ì´ëŠ” ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì˜ ê´€ì¸¡ ë°ì´í„°ë¥¼ ì„¤ëª…í•˜ëŠ”ì§€ í‰ê°€í•˜ëŠ” ë° ì¤‘ìš”)
  - Solution : `Forward Algorithm`
  - example : ì˜¤ëŠ˜ ì‚°ì±…, ë‚´ì¼ ì‚°ì±…, ëª¨ë ˆ ì—°êµ¬, ê¸€í”¼ ì‡¼í•‘í•  í™•ë¥ ì€?
  - Forward probability (ì „ë°© í™•ë¥ , $\alpha_{t}(i)$ ) = $p(O| \lambda) = \sum_{i=1}^{n} \alpha_{T}(j)$
    - ìˆœì°¨ì ìœ¼ë¡œ (ë’¤ -> ì•ìœ¼ë¡œ) ê³„ì‚°
    - 1. $a_1(i) = \pi_i b_i(o_1)$ , $1 \leq i \leq n$
    - 2. $a_{t}(i) = [\sum_{j=1}^{n} a_{t-1}(j) a_{ji}] b_i(o_t)$, $2 \leq t \leq T, 1 \leq i \leq n$
      - $ë°”ë¡œ ì§ì „ ìƒíƒœ state * eventê°€ ê´€ì¸¡ë  í™•ë¥ $
- Forward probabilityëŠ” ì£¼ì–´ì§„ Sequence Oê°€ HMMì— ì†í•  í™•ë¥  ë¬¸ì œì— í™œìš© ê°€ëŠ¥
  - HMM1ê³¼ HMM2ê°€ ìˆì„ ë•Œ ì–´ëŠ HMMì— ì†í•  í™•ë¥ ì´ ë†’ì„ì§€?
  - Sequence classification ë¬¸ì œì— í™œìš© ê°€ëŠ¥

### Decoding problem (HMMì˜ í•µì‹¬)

- Problem : HMM($\lambda^*$)ì™€ O(Observable sequence)ê°€ ì£¼ì–´ì¡Œì„ ë•Œ ìµœì ì˜ S(hidden state sqence)ê²°ì •(ê°€ì¥ ê·¸ëŸ´ì‹¸í•œ ì€ë‹‰ ìƒíƒœ ì‹œí€€ìŠ¤ ê²°ì •)

  - Solution : `Viterbi Algorithm`
  - example : ì˜¤ëŠ˜ ì‚°ì±…, ë‚´ì¼ ì‚°ì±…, ëª¨ë ˆ ì—°êµ¬, ê¸€í”¼ ì‡¼í•‘ì„ í–ˆë‹¤ë©´ ê° ë‚ ë“¤ ë‚ ì”¨ëŠ”?
  - Viterbi Algorithm for Decoding problem
    - ì „ë°© ê³„ì‚° (ë§¤ ë‹¨ê³„ì—ì„œ ìµœì  ê²½ë¡œ ê¸°ë¡)
      - $v_{t}(i) = max_{q_1, q_2, ..., q_{t-1}} p(o_1, o_2, ..., o_t, q_1, q_2, ..., q_{t-1}, q_t = s_i | \lambda)$ = $max_{1 \leq j \leq n} [v_{t-1}(j) a_{ji}] b_i(o_t)$ / $2 \leq t \leq T, 1 \leq i \leq n$
      - $v_1(i) = \pi_i b_i(o_1)$
    - ìµœì  ê²½ë¡œ ì¶”ì 
      - $\hat q*{T} = argmax*{1 \leq j \leq n} (v\_{T}(j))$
      - $\hat Q*{t} = (\hat q*{1}, \hat q*{2}, ..., \hat q*{t})$

- Learning problem

#### Evaluation vs Decoding

- Forward Algorithm for Evaluation : ê°€ëŠ¥í•œ ëª¨ë“  ê²½ìš°ì˜ í™•ë¥  í•©
  - Observable stateì˜ í™•ë¥ ì„ êµ¬í•˜ëŠ” ê²ƒì´ ëª©í‘œ
- Viterbi Algorithm for Evaluation : ê°€ëŠ¥í•œ ëª¨ë“  ê²½ìš°ì˜ í™•ë¥  **ìµœëŒ€** ê°€ì¥ ê·¸ëŸ´ì‹¸í•œ ìƒíƒœë¥¼ ì°¾ëŠ” ê²ƒ
